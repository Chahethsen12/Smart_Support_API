{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyPp1E8VLxS0nQYtoaA2M9F+",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Chahethsen12/Smart_Support_API/blob/main/Smart_Support_API.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Install Industrial Libraries"
      ],
      "metadata": {
        "id": "2l3Qt3WxPTHk"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "zeG9_vvOPQUV"
      },
      "outputs": [],
      "source": [
        "!pip install -q fastapi uvicorn pyngrok nest_asyncio transformers torch\n",
        "print(\"FastAPI & AI Environment Ready!\")"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "The Full Stack Application"
      ],
      "metadata": {
        "id": "GRLdTtRUPkhF"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import nest_asyncio\n",
        "import uvicorn\n",
        "from fastapi import FastAPI, HTTPException\n",
        "from pydantic import BaseModel\n",
        "from transformers import pipeline\n",
        "from typing import List, Optional\n",
        "import sqlite3\n",
        "from datetime import datetime\n",
        "\n",
        "# 1. THE AI ENGINE (HuggingFace)\n",
        "# We use a lightweight model to classify text without needing an API key\n",
        "print(\"‚è≥ Loading AI Models... (This takes 30 seconds)\")\n",
        "classifier = pipeline(\"zero-shot-classification\", model=\"facebook/bart-large-mnli\")\n",
        "sentiment_analyzer = pipeline(\"sentiment-analysis\", model=\"distilbert-base-uncased-finetuned-sst-2-english\")\n",
        "print(\"‚úÖ AI Models Loaded!\")\n",
        "\n",
        "# 2. DATA MODELS (Pydantic - The Industrial Standard)\n",
        "class TicketCreate(BaseModel):\n",
        "    customer_name: str\n",
        "    email: str\n",
        "    issue_description: str\n",
        "\n",
        "class TicketResponse(BaseModel):\n",
        "    id: int\n",
        "    category: str\n",
        "    priority: str\n",
        "    sentiment: str\n",
        "    status: str\n",
        "\n",
        "# 3. DATABASE SETUP (SQLite)\n",
        "conn = sqlite3.connect('support_tickets.db', check_same_thread=False)\n",
        "c = conn.cursor()\n",
        "c.execute('''CREATE TABLE IF NOT EXISTS tickets\n",
        "             (id INTEGER PRIMARY KEY, customer_name TEXT, issue_description TEXT,\n",
        "              category TEXT, priority TEXT, sentiment TEXT, status TEXT)''')\n",
        "conn.commit()\n",
        "\n",
        "# 4. THE API APP\n",
        "app = FastAPI(title=\"SmartHelp AI API\", description=\"Automated Ticket Triage System\")\n",
        "\n",
        "@app.post(\"/tickets/\", response_model=TicketResponse)\n",
        "async def create_ticket(ticket: TicketCreate):\n",
        "    # --- INDUSTRIAL LOGIC START ---\n",
        "\n",
        "    # A. AI Analysis\n",
        "    # 1. Classify the topic\n",
        "    labels = [\"billing\", \"technical support\", \"feature request\", \"spam\"]\n",
        "    classification = classifier(ticket.issue_description, labels)\n",
        "    category = classification['labels'][0]\n",
        "\n",
        "    # 2. Analyze Sentiment (Is the customer angry?)\n",
        "    sentiment_result = sentiment_analyzer(ticket.issue_description)[0]\n",
        "    sentiment_score = sentiment_result['label'] # POSITIVE or NEGATIVE\n",
        "\n",
        "    # B. Business Logic (Rule-based)\n",
        "    priority = \"NORMAL\"\n",
        "    if category == \"billing\" or sentiment_score == \"NEGATIVE\":\n",
        "        priority = \"URGENT\"\n",
        "\n",
        "    # C. Save to Database\n",
        "    c.execute(\"INSERT INTO tickets (customer_name, issue_description, category, priority, sentiment, status) VALUES (?, ?, ?, ?, ?, ?)\",\n",
        "              (ticket.customer_name, ticket.issue_description, category, priority, sentiment_score, \"OPEN\"))\n",
        "    conn.commit()\n",
        "    ticket_id = c.lastrowid\n",
        "\n",
        "    # --- INDUSTRIAL LOGIC END ---\n",
        "\n",
        "    return {\n",
        "        \"id\": ticket_id,\n",
        "        \"category\": category,\n",
        "        \"priority\": priority,\n",
        "        \"sentiment\": sentiment_score,\n",
        "        \"status\": \"OPEN\"\n",
        "    }\n",
        "\n",
        "@app.get(\"/tickets/\")\n",
        "async def get_tickets():\n",
        "    c.execute(\"SELECT * FROM tickets\")\n",
        "    rows = c.fetchall()\n",
        "    return [{\"id\": r[0], \"customer\": r[1], \"issue\": r[2], \"category\": r[3], \"priority\": r[4], \"sentiment\": r[5]} for r in rows]\n",
        "\n",
        "# Allow Colab to run this async\n",
        "nest_asyncio.apply()"
      ],
      "metadata": {
        "id": "Fl4mZrxjPosN"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Run the Server"
      ],
      "metadata": {
        "id": "W3vRC-vvPq8S"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from threading import Thread\n",
        "\n",
        "def run_server():\n",
        "    uvicorn.run(app, host=\"0.0.0.0\", port=8000)\n",
        "\n",
        "# Start server in a background thread\n",
        "thread = Thread(target=run_server)\n",
        "thread.start()\n",
        "\n",
        "print(\"üöÄ Server is running in the background!\")\n",
        "print(\"Since we are in Colab, we can't visit localhost directly.\")\n",
        "print(\"Run the NEXT CELL to test your API.\")"
      ],
      "metadata": {
        "id": "q1sN_NXgPuNe"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Test Your \"Full Stack\" Logic"
      ],
      "metadata": {
        "id": "PNkrupGxPwIQ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import requests\n",
        "import json\n",
        "\n",
        "# 1. Simulate a User submitting a ticket\n",
        "url = \"http://127.0.0.1:8000/tickets/\"\n",
        "\n",
        "payload = {\n",
        "    \"customer_name\": \"John Doe\",\n",
        "    \"email\": \"john@example.com\",\n",
        "    \"issue_description\": \"My credit card was charged twice! I am very angry about this service.\"\n",
        "}\n",
        "\n",
        "print(\"üì§ Sending Ticket to API...\")\n",
        "response = requests.post(url, json=payload)\n",
        "\n",
        "print(\"\\nüì• API Response (AI Analysis):\")\n",
        "print(json.dumps(response.json(), indent=2))\n",
        "\n",
        "# Check the results:\n",
        "# Did the AI catch that John is angry?\n",
        "# Did it mark it as Billing?\n",
        "# Did it mark it as URGENT?"
      ],
      "metadata": {
        "id": "vF0oRLSPPz34"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}